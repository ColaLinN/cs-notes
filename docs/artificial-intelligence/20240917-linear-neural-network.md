

# Linear Neural Network

## è¦ç‚¹

1. çº¿æ€§ç¥ç»ç½‘ç»œæ¨¡å‹
   1. å›å½’æ¨¡å‹ï¼šçº¿æ€§å›å½’ Linear Regression
   2. åˆ†ç±»æ¨¡å‹ï¼šSoftmax

2. ç¥ç»ç½‘ç»œæ¶æ„
3. æ•°æ®å¤„ç†
4. æŸå¤±å‡½æ•° Loss Function
5. æ¢¯åº¦ä¸‹é™ï¼Œå°æ¢¯åº¦æ‰¹é‡ä¸‹é™
6. å®šä¹‰ä¼˜åŒ–ç®—æ³•

## çº¿æ€§å›å½’ Linear Regression

### ç¥ç»ç½‘ç»œå›¾

å°†çº¿æ€§å›å½’æ¨¡å‹å¯è§†åŒ–ä¸ºä¸€ä¸ªç¥ç»ç½‘ç»œã€‚åªæ˜¾ç¤ºè¿æ¥æ¨¡å¼ï¼Œå³æ¯ä¸ªè¾“å…¥å¦‚ä½•è¿æ¥åˆ°è¾“å‡ºï¼Œéšå»æƒé‡å’Œåç½®çš„å€¼ã€‚

![image-20240919014810350](./20240917-linear-neural-network.assets/image-20240919014810350.png)

å›¾ä¸­è¦ç‚¹

- è¾“å…¥å±‚ä¸º `x1,x2,...,xd` ä¸º d ç»´ï¼Œè¾“å‡ºå±‚ `01` ä¸º 1 ç»´
- ç»Ÿè®¡ç½‘ç»œå±‚æ•°æ—¶ä¼šå¿½ç•¥è¾“å…¥å±‚ï¼Œæ‰€ä»¥è¿™ä¸ªç¥ç»ç½‘ç»œæ˜¯ 1 å±‚
- è¿™æ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼ˆfully-connected layerï¼‰æˆ–ç§°ä¸ºç¨ å¯†å±‚ï¼ˆdense layerï¼‰ï¼Œå³æ¯ä¸ªè¾“å…¥ä¸æ¯ä¸ªè¾“å‡ºç›¸è¿

### çº¿æ€§å‡½æ•°

![image-20240919012630147](./20240917-linear-neural-network.assets/image-20240919012630147.png)

![image-20240919012636948](./20240917-linear-neural-network.assets/image-20240919012636948.png)

![image-20240919012641985](./20240917-linear-neural-network.assets/image-20240919012641985.png)

ç»™å®šä¸€ç»„è®­ç»ƒæ•°æ®ç‰¹å¾ X å’Œå·²çŸ¥çš„å¯¹åº”çš„å·²çŸ¥æ ‡ç­¾ yï¼Œçº¿æ€§å›å½’çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ç»„æƒé‡å‘é‡ w å’Œåç½® b ä½¿å¾—å¯¹æ–°æ ·æœ¬çš„é¢„æµ‹è¯¯å·®å°½å¯èƒ½å°ã€‚

å‚æ•°è¯¦è§£

- è®­ç»ƒæ•°æ®ç‰¹å¾ X
- å·²çŸ¥æ ‡ç­¾ y
- æƒé‡å‘é‡ w
- åç½® b

### åº¦é‡æ¨¡å‹ï¼ŒæŸå¤±å‡½æ•°ï¼Œå¹³æ–¹è¯¯å·®

éœ€è¦ç¡®å®šä¸€ä¸ªæ‹Ÿåˆç¨‹åº¦çš„åº¦é‡ã€‚ æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰èƒ½å¤Ÿé‡åŒ–ç›®æ ‡çš„å®é™…å€¼ä¸é¢„æµ‹å€¼ä¹‹é—´çš„å·®è·ã€‚ä¼šé€‰æ‹©éè´Ÿæ•°ä½œä¸ºæŸå¤±ï¼Œä¸”æ•°å€¼è¶Šå°è¡¨ç¤ºæŸå¤±è¶Šå°ï¼Œå®Œç¾é¢„æµ‹æ—¶çš„æŸå¤±ä¸º0ã€‚  

å›å½’é—®é¢˜ä¸­æœ€å¸¸ç”¨çš„æŸå¤±å‡½æ•°æ˜¯å¹³æ–¹è¯¯å·®å‡½æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤º

- `^y` ä¸ºé¢„æµ‹å€¼
- `y` ä¸ºçœŸå®å€¼

![image-20240919013130296](./20240917-linear-neural-network.assets/image-20240919013130296.png)

å¯¹äºæ¨¡å‹åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šçš„è´¨é‡ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—åœ¨è®­ç»ƒé›† n ä¸ªæ ·æœ¬ä¸Šçš„æŸå¤±å‡½æ•°ï¼ˆç­‰ä»·äºæ±‚å’Œï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤º

![image-20240919013400051](./20240917-linear-neural-network.assets/image-20240919013400051.png)

æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æœ€å°åŒ–è¿™ä¸ªæŸå¤±å‡½æ•°ï¼Œæ‰¾åˆ°æœ€ä½³çš„å‚æ•° w å’Œåç½® bï¼Œå¦‚ä¸‹æ‰€ç¤º

![image-20240919013413116](./20240917-linear-neural-network.assets/image-20240919013413116.png)

### æ›´æ–°æ¨¡å‹ï¼Œè®­ç»ƒæ–¹æ³•ï¼Œæ¢¯åº¦ä¸‹é™æœ€å°åŒ–æŸå¤±å‡½æ•°

æœ‰ä¸¤ç§æ–¹å¼

- è§£æè§£
  - çº¿æ€§å›å½’çš„è§£å¯ä»¥ç”¨ä¸€ä¸ªå…¬å¼ç®€å•åœ°è¡¨è¾¾å‡ºæ¥ï¼Œ è¿™ç±»è§£å«ä½œè§£æè§£ï¼ˆanalytical solutionï¼‰ï¼Œä½†å¹¶ä¸æ˜¯æ‰€æœ‰çš„é—®é¢˜éƒ½å­˜åœ¨è§£æè§£ã€‚
- éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆstochastic gradient descent, SGDï¼‰ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚
  - å³ä½¿æ— æ³•å¾—åˆ°è§£æè§£ï¼Œä½†æ¢¯åº¦ä¸‹é™å‡ ä¹å¯ä»¥ä¼˜åŒ–æ‰€æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡åœ¨æŸå¤±å‡½æ•°é€’å‡çš„æ–¹å‘ä¸Šæ›´æ–°å‚æ•°æ¥é™ä½è¯¯å·®ã€‚è®¡ç®—æŸå¤±å‡½æ•°ï¼ˆæ•°æ®é›†ä¸­æ‰€æœ‰æ ·æœ¬çš„æŸå¤±å‡å€¼ï¼‰ å…³äºæ¨¡å‹å‚æ•°çš„å¯¼æ•°ï¼ˆä¹Ÿå¯ä»¥ç§°ä¸ºæ¢¯åº¦ï¼‰ã€‚
  - æ–¹æ³•ï¼ˆ1ï¼‰åˆå§‹åŒ–æ¨¡å‹å‚æ•°çš„å€¼ï¼Œå¦‚éšæœºåˆå§‹åŒ–ï¼› ï¼ˆ2ï¼‰ä»æ•°æ®é›†ä¸­éšæœºæŠ½å–å°æ‰¹é‡æ ·æœ¬ä¸”åœ¨è´Ÿæ¢¯åº¦çš„æ–¹å‘ä¸Šæ›´æ–°å‚æ•°ï¼Œå¹¶ä¸æ–­è¿­ä»£è¿™ä¸€æ­¥éª¤ã€‚
- Adam optimizer

![image-20240919014212929](./20240917-linear-neural-network.assets/image-20240919014212929.png)

ä¸Šå›¾ä¸­æ¢¯åº¦ä¸‹é™çš„å‚æ•°è¯¦è§£ï¼ˆè¶…å‚æ•°ï¼‰

- `|B|` è¡¨ç¤ºæ¯ä¸ªå°æ‰¹é‡ä¸­çš„æ ·æœ¬æ•°ï¼Œè¿™ä¹Ÿç§°ä¸ºæ‰¹é‡å¤§å°ï¼ˆbatch sizeï¼‰
- ` ğœ‚` è¡¨ç¤ºå­¦ä¹ ç‡ï¼ˆlearning rateï¼‰

### æ¨¡å‹é¢„æµ‹ï¼Œæ¨ç†

ç»™å®šçº¿æ€§å›å½’æ¨¡å‹ `wx+b`ï¼Œå¯ä»¥é€šè¿‡ `x` æ¥è®¡ç®— `y`ï¼Œç»™å®šç‰¹å¾ä¼°è®¡ç›®æ ‡çš„è¿‡ç¨‹é€šå¸¸ç§°ä¸ºé¢„æµ‹ï¼ˆpredictionï¼‰æˆ–æ¨ç†ï¼ˆinferenceï¼‰ã€‚

### ä»£ç ï¼ˆTODOï¼‰

```python
%matplotlib inline
import random
import torch
from d2l import torch as d2l

# ç”Ÿæˆæ•°æ®é›†
def synthetic_data(w, b, num_examples):  #@save
    """ç”Ÿæˆy=Xw+b+å™ªå£°"""
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)

d2l.set_figsize()
d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1);

def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    # è¿™äº›æ ·æœ¬æ˜¯éšæœºè¯»å–çš„ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡ºåº
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])
        yield features[batch_indices], labels[batch_indices]
        
batch_size = 10

for X, y in data_iter(batch_size, features, labels):
    print(X, '\n', y)
    break
```

æ¨¡å‹è®­ç»ƒ

```python
# åˆå§‹åŒ–æ¨¡å‹å‚æ•°
w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)

def linreg(X, w, b):  #@save
    """çº¿æ€§å›å½’æ¨¡å‹"""
    return torch.matmul(X, w) + b
  
def squared_loss(y_hat, y):  #@save
    """å‡æ–¹æŸå¤±"""
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2

def sgd(params, lr, batch_size):  #@save
    """å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™"""
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()

lr = 0.03
num_epochs = 3
net = linreg
loss = squared_loss

for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)  # Xå’Œyçš„å°æ‰¹é‡æŸå¤±
        # å› ä¸ºlå½¢çŠ¶æ˜¯(batch_size,1)ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚lä¸­çš„æ‰€æœ‰å…ƒç´ è¢«åŠ åˆ°ä¸€èµ·ï¼Œ
        # å¹¶ä»¥æ­¤è®¡ç®—å…³äº[w,b]çš„æ¢¯åº¦
        l.sum().backward()
        sgd([w, b], lr, batch_size)  # ä½¿ç”¨å‚æ•°çš„æ¢¯åº¦æ›´æ–°å‚æ•°
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')

print(f'wçš„ä¼°è®¡è¯¯å·®: {true_w - w.reshape(true_w.shape)}')
print(f'bçš„ä¼°è®¡è¯¯å·®: {true_b - b}')
```

## çº¿æ€§å›å½’å…¶ä»–

### æœ€å°åŒ–å‡æ–¹è¯¯å·®å³æœ€å¤§ä¼¼ç„¶ä¼°è®¡

å‡è®¾æœ‰ä¸€ä¸ªæ¨¡å‹ï¼Œç”¨ `P(X|Î¸)` è¡¨ç¤ºï¼Œå…¶ä¸­ X æ˜¯è§‚æµ‹æ•°æ®ï¼ŒÎ¸ æ˜¯æ¨¡å‹å‚æ•°ã€‚è¿™é‡Œ `P(X|Î¸)` è¡¨ç¤ºç»™å®šå‚æ•° Î¸ æ—¶ï¼Œè§‚æµ‹åˆ°æ•°æ® X çš„æ¦‚ç‡ã€‚å½“æˆ‘ä»¬è§‚æµ‹åˆ° X å¸Œæœ›ä¼°è®¡æœªçŸ¥å‚æ•° Î¸ æ—¶ï¼Œç§° `L(Î¸|X)` ä¸ºä¼¼ç„¶å‡½æ•°ï¼ˆlikelihood functionï¼‰ï¼Œæœ‰ `P(X|Î¸)=L(Î¸|X)`ã€‚

æœ€å¤§ä¼¼ç„¶ä¼°è®¡

- ä¼¼ç„¶è¡¨ç¤ºæŸä¸ªæ¨¡å‹å‚æ•°åœ¨ç»™å®šè§‚æµ‹æ•°æ®çš„æƒ…å†µä¸‹è§£é‡Šæ•°æ®çš„èƒ½åŠ›ï¼Œä¼¼ç„¶å‡½æ•°å–å¾—æœ€å¤§å€¼è¡¨ç¤ºç›¸åº”çš„å‚æ•°èƒ½å¤Ÿä½¿å¾—ç»Ÿè®¡æ¨¡å‹æœ€ä¸ºåˆç†ã€‚
- åœ¨é«˜æ–¯å™ªå£°çš„å‡è®¾ä¸‹ï¼Œæœ€å°åŒ–å‡æ–¹è¯¯å·®ç­‰ä»·äºå¯¹çº¿æ€§æ¨¡å‹çš„æå¤§ä¼¼ç„¶ä¼°è®¡ã€‚

å‡å¦‚æ·ç¡¬å¸æ­£é¢æœä¸Šçš„æ¦‚ç‡æ˜¯ PHï¼Œæˆ‘ä»¬æ·ç¡¬å¸ä¸‰æ¬¡ï¼Œä¸¤æ¬¡æ­£é¢æœä¸Šï¼Œä¸€æ¬¡åé¢æœä¸Šçš„ä¼¼ç„¶å‡½æ•°å¦‚ä¸‹ï¼Œä»å‡½æ•°å›¾åƒä¸­å¯ä»¥å¾—çŸ¥ï¼ŒPH ä¸º `2/3` æ—¶è¾¾åˆ°æœ€å¤§ä¼¼ç„¶å‡½æ•°å€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥çŒœæµ‹ PH ä¸º `2/3`

![image-20240919011809337](./20240917-linear-neural-network.assets/image-20240919011809337.png)

![image-20240919012436134](./20240917-linear-neural-network.assets/image-20240919012436134.png)

## çº¿æ€§åˆ†ç±» Softmax

å›å½’å¯ä»¥ç”¨äºé¢„æµ‹å¤šå°‘çš„é—®é¢˜ã€‚ æ¯”å¦‚é¢„æµ‹æˆ¿å±‹è¢«å”®å‡ºä»·æ ¼ã€‚å¦‚æœè¦é¢„æµ‹ç±»åˆ«ï¼Œæ¯”å¦‚æŸä¸ªç”µå­é‚®ä»¶æ˜¯å¦å±äºåƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹ï¼Œå°±éœ€è¦åˆ†ç±»æ¨¡å‹ã€‚

### ç¥ç»ç½‘ç»œå›¾

ä¸ºäº†è§£å†³çº¿æ€§æ¨¡å‹çš„åˆ†ç±»é—®é¢˜ï¼Œéœ€è¦ä¸€ä¸ªæœ‰å¤šè¾“å‡ºçš„æ¨¡å‹ï¼Œæ¯ä¸ªç±»åˆ«å¯¹åº”ä¸€ä¸ªè¾“å‡ºã€‚ æˆ‘ä»¬éœ€è¦å’Œè¾“å‡ºä¸€æ ·å¤šçš„ä»¿å°„å‡½æ•°ï¼ˆaffine functionï¼‰ï¼Œæ¯ä¸ªè¾“å‡ºå¯¹åº”äºå®ƒè‡ªå·±çš„ä»¿å°„å‡½æ•°ã€‚

![image-20240923091834288](./20240917-linear-neural-network.assets/image-20240923091834288.png)

å‡è®¾æœ‰ 4 ä¸ªè¾“å…¥ï¼Œ3 ä¸ªè¾“å‡ºï¼Œåˆ™éœ€è¦ 3 ä¸ªå‡½æ•°ï¼Œæ€»å…± 12 ä¸ªå‚æ•°ã€‚æ³›åŒ–ä¸ºå‡½æ•° `o=Wx+b`ã€‚ 

![image-20240923092122736](./20240917-linear-neural-network.assets/image-20240923092122736.png)

æ‰€ä»¥æˆ‘ä»¬å¯ä»¥æ ¹æ®æ¦‚ç‡çš„å¤§å°åˆ¤æ–­ y çš„ç±»åˆ«ï¼Œä½†æ˜¯å…¨è¿æ¥å±‚è¾“å‡ºåˆ™æœ‰å¯èƒ½æ˜¯è´Ÿçš„ï¼Œä¸”æ€»å’Œä¸å”¯ä¸€ã€‚

ç”±æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ Softmax å‡½æ•°æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒSoftmax å‡½æ•°å¦‚ä¸‹æ‰€ç¤º

- å°†æœªè§„èŒƒåŒ–çš„è¾“å‡ºå˜ä¸ºéè´Ÿæ•°ã€ä¸”æ€»å’Œä¸º1ã€‚
- è®©æ¨¡å‹ä¿æŒå¯å¯¼çš„æ€§è´¨ï¼ˆtodoï¼šwhyï¼Ÿand whatï¼Ÿï¼‰

![image-20240923092513922](./20240917-linear-neural-network.assets/image-20240923092513922.png)

å¦‚æœè¦é¢„æµ‹æœ€æœ‰å¯èƒ½çš„ç±»åˆ«ï¼Œå¯ä»¥é€šè¿‡æ±‚æœ€å¤§çš„ yj æ‰¾åˆ°ç±»åˆ« jï¼Œå¦‚ä¸‹æ‰€ç¤º

![image-20240923092952479](./20240917-linear-neural-network.assets/image-20240923092952479.png)

å°½ç®¡softmaxæ˜¯ä¸€ä¸ªéçº¿æ€§å‡½æ•°ï¼Œä½†softmaxå›å½’çš„è¾“å‡ºä»ç„¶ç”±è¾“å…¥ç‰¹å¾çš„ä»¿å°„å˜æ¢å†³å®šã€‚ å› æ­¤ softmaxå›å½’æ˜¯ä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼ˆlinear modelï¼‰ã€‚

### æŸå¤±å‡½æ•°ï¼Œäº¤å‰ç†µæŸå¤±

äº¤å‰ç†µæŸå¤±ï¼ˆcross-entropy lossï¼‰ã€‚æœ€å¥½çš„æƒ…å†µä¸‹ï¼Œå¦‚æœ `yj^` ä¸º 1ï¼Œæ‰€ä»¥å…¶å¯¹æ•°ä¸º 0ï¼ŒæŸå¤±å€¼æœ€ä½ä¸º 0ã€‚

- `yj` ä¸ºçœŸå®æ ‡ç­¾ï¼Œä¸ºåŒ…å«äºŒå…ƒé¡¹çš„å‘é‡ `(0,0,1)`
- `yj^` ä¸ºé¢„æµ‹æ ‡ç­¾ï¼Œä¸ºä¸€ä¸ªæ¦‚ç‡å‘é‡è¡¨ç¤ºï¼Œå¦‚ `(0.1,0.2,0.7)`

![image-20240923121309146](./20240917-linear-neural-network.assets/image-20240923121309146.png)

å°† Softmax å‡½æ•°ä»£å…¥å¯å¾—

![image-20240923122546785](./20240917-linear-neural-network.assets/image-20240923122546785.png)

æ­¤æŸå¤±å‡½æ•°çš„å¯¼æ•°å¦‚ä¸‹ã€‚å¯ä»¥çœ‹å‡ºï¼Œå¯¼æ•°æ˜¯é¢„æµ‹æ ‡ç­¾ä¸çœŸå®æ ‡ç­¾çš„å·®å¼‚ã€‚

![image-20240923123007904](./20240917-linear-neural-network.assets/image-20240923123007904.png)

### æ¨¡å‹é¢„æµ‹ä¸è¯„ä¼°

é¢„æµ‹ï¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ä½œä¸ºè¾“å‡ºç±»åˆ«ï¼Œå¦‚æœé¢„æµ‹ä¸å®é™…ç±»åˆ«ä¸€è‡´ï¼Œåˆ™é¢„æµ‹æ˜¯å¯¹çš„ã€‚

è¯„ä¼°ï¼šé€šè¿‡ç²¾åº¦ï¼ˆAccuracyï¼‰æ¥è¯„ä¼°æ¨¡å‹çš„æ•ˆæœã€‚

```
accuracy = æ­£ç¡®é¢„æµ‹æ•° / é¢„æµ‹æ€»æ•°
```

## Softmax å…¶ä»–

### ç‹¬çƒ­ç¼–ç ï¼ˆtodoï¼‰

ä¸ºäº†è¡¨ç¤ºè¾“å‡ºç±»åˆ« yï¼Œæˆ‘ä»¬ä½¿ç”¨ç‹¬çƒ­ç¼–ç ï¼ˆy1, y2, y3ï¼‰æ¥è¡¨ç¤ºã€‚

### å…¨è¿æ¥å±‚

åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå…¨è¿æ¥å±‚æ— å¤„ä¸åœ¨ã€‚å…¨è¿æ¥å±‚æ˜¯â€œå®Œå…¨â€è¿æ¥çš„ï¼Œæœ‰å¾ˆå¤šå¯å­¦ä¹ çš„å‚æ•°ã€‚æ¯”å¦‚çº¿æ€§å›å½’ LR å’Œ çº¿æ€§åˆ†ç±» Softmax éƒ½æ˜¯å…¨è¿æ¥å±‚ã€‚

### äº¤å‰ç†µä¿¡æ¯é‡åŸºç¡€

ä¿¡æ¯è®ºï¼ˆinformation theoryï¼‰æ¶‰åŠç¼–ç ã€è§£ç ã€å‘é€ä»¥åŠå°½å¯èƒ½ç®€æ´åœ°å¤„ç†ä¿¡æ¯æˆ–æ•°æ®ã€‚

ä¿¡æ¯è®ºçš„æ ¸å¿ƒæ€æƒ³æ˜¯é‡åŒ–æ•°æ®ä¸­çš„ä¿¡æ¯å†…å®¹ï¼Œè¿™è¢«ç§°ä½œç†µï¼ˆentropyï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤º

![image-20240923123401934](./20240917-linear-neural-network.assets/image-20240923123401934.png)

ä¸ºäº†å¯¹ä»åˆ†å¸ƒ `P` ä¸­éšæœºæŠ½å–çš„æ•°æ®è¿›è¡Œç¼–ç ï¼Œ æˆ‘ä»¬è‡³å°‘éœ€è¦ `H[P]` â€œçº³ç‰¹ï¼ˆnatï¼‰â€å¯¹å…¶è¿›è¡Œç¼–ç ï¼Œâ€œçº³ç‰¹â€ç›¸å½“äºæ¯”ç‰¹ï¼ˆbitï¼‰ï¼Œå…¶åº•ä¸º eã€‚

- ç†µè¡¨ç¤ºäº†ä¸€ä¸ªæ•°æ®çš„ä¿¡æ¯é‡ï¼Œåœ¨å‹ç¼©æ•°æ®å’Œä¼ è¾“æ•°æ®çš„è¿‡ç¨‹ä¸­ï¼Œä¸€ä¸ªäº‹ä»¶å‡ºç°çš„é¢‘ç‡è¶Šä½ï¼Œå…¶ä¿¡æ¯é‡è¶Šå¤§ã€‚
- è€Œäº¤å‰ç†µä¸ºï¼Œä¸»è§‚æ¦‚ç‡ä¸º Q çš„è§‚å¯Ÿè€…åœ¨è§‚å¯Ÿæ ¹æ®æ¦‚ç‡ P ç”Ÿæˆæ•°æ®æ—¶çš„æƒŠè®¶ç¨‹åº¦ï¼Œå½“ `P = Q` æ—¶ï¼Œäº¤å‰ç†µè¾¾åˆ°æœ€ä½ã€‚

## Reference

1. [åŠ¨æ‰‹å­¦ä¹ æ·±åº¦å­¦ä¹  by limu](https://zh-v2.d2l.ai/chapter_linear-networks/linear-regression.html#id4)
