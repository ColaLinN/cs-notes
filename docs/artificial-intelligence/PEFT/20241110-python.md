

选中即为true的argument

```
parser.add_argument("--no-lora-compute", action="store_true")
```



socket

使用了 **ZeroMQ（zmq）** 库和 **asyncio**，来设置一个基于 **ZeroMQ** 的异步通信管道。它创建了两个 ZeroMQ 的 socket，一个用于 `PUSH` 类型的消息发送，一个用于 `PULL` 类型的消息接收。这些 socket 的作用是将消息在不同组件之间进行路由和传递。以下是代码的详细解释：

```
        # 创建了一个 ZeroMQ 异步上下文，用于管理 socket。Context(2) 表示该上下文下的 I/O 线程数为 2。
        context = zmq.asyncio.Context(2)
        # http server push -> pull router push -> pull detokenization push -> pull http server
        self.send_to_router = context.socket(zmq.PUSH)
        self.send_to_router.connect(f"tcp://127.0.0.1:{router_port}")

        self.recv_from_detokenization = context.socket(zmq.PULL)
        self.recv_from_detokenization.bind(f"tcp://127.0.0.1:{httpserver_port}")
```



router init

```
    async def wait_to_model_ready(self):
        self.model_rpcs: List[ModelRpcClient] = []
        for rank_id in range(self.world_size):
            rpc_model = await start_model_process(port=self.model_rpc_ports[rank_id], world_size=self.world_size)
            self.model_rpcs.append(rpc_model)

        init_model_ret = []
        for rank_id in range(self.world_size):  # async init model process
            # 每个任务都是对 init_model 方法的调用，该方法会在远程模型进程中初始化模型。
            # init_model 方法返回一个异步任务对象，表示这个初始化任务将异步运行。每个任务对象被添加到 init_model_ret 列表中。
            init_model_ret.append(
                self.model_rpcs[rank_id].init_model(
                    rank_id,
                    self.world_size,
                    self.model_weightdir,
                    self.adapter_dirs,
                    self.input_params.max_total_token_num,
                    self.load_way,
                    self.mode,
                    input_params=self.input_params,
                    prefetch_stream=self.prefetch_stream,
                ))
        # 如果 world_size == 1，那么 init_model_ret 的 use_rpc 为 false
        # 如果 use_rpc 为 False，则 init_model 不会返回一个实际的 awaitable 对象，因此 asyncio.gather 会立即视其为完成，不会阻塞。
        # await asyncio.gather(*init_model_ret)
        await asyncio.gather(*init_model_ret)
        return
```

## `torch.cuda.synchronize()` 的作用

`torch.cuda.synchronize()` 是 PyTorch 中的一个函数，用于在 GPU 上执行**同步操作**。在使用 GPU 进行计算时，许多操作是异步执行的，这样可以提高效率。但有时我们需要确保所有 GPU 操作都已经完成，尤其是在依赖前一个操作结果或进行性能测量时，这时 `torch.cuda.synchronize()` 就非常有用。

- **同步 GPU 操作**：它会阻塞当前代码的执行，直到所有在 GPU 上排队的计算操作完成。这意味着在 `torch.cuda.synchronize()` 之后，所有 GPU 操作都已完成，不再有未处理的操作。
- **确保数据一致性**：在某些情况下，后续代码依赖 GPU 上的计算结果，而 GPU 操作是异步执行的，所以需要 `torch.cuda.synchronize()` 来保证在继续后续操作之前所有计算都已完成。
- **性能测试**：在进行性能测量或记录执行时间时，通常需要使用 `torch.cuda.synchronize()` 来确保测量的时刻是所有 GPU 操作完成后的真实状态。

`torch.cuda.synchronize()` 在这段代码中用于确保 GPU 上的操作按顺序完成，特别是在执行模型合并和批处理填充时，确保数据一致性。通过这种方式，可以避免异步计算带来的潜在数据冲突，并保证后续操作在预期状态下执行。